{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size: 48px; color:rgb(222, 238, 255)ign: center;\">üè° House Price Prediction</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [Exploratory Data Analysis](#toc1_)    \n",
    "  - [Feature Descriptions](#toc1_1_)    \n",
    "  - [Handeling Missing Values](#toc1_2_)    \n",
    "    - [Plotting Null Values in Object Columns](#toc1_2_1_)    \n",
    "    - [Plotting Null Values in Numeric Columns](#toc1_2_2_)    \n",
    "  - [Explore Categorical Features](#toc1_3_)    \n",
    "    - [Sort by Mean Price](#toc1_3_1_)    \n",
    "  - [Feature Manipulation](#toc1_4_)    \n",
    "    - [Feature Engeneering -](#toc1_4_1_)    \n",
    "    - [Label Encoding -](#toc1_4_2_)    \n",
    "    - [Target Encoding (LOO) -](#toc1_4_3_)    \n",
    "  - [Explore Numerical Features](#toc1_5_)    \n",
    "    - [Remove Outliers](#toc1_5_1_)    \n",
    "- [Training and Testing Linear Models](#toc2_)    \n",
    "  - [Filter by Correlation](#toc2_1_)    \n",
    "  - [Prepare for Training](#toc2_2_)    \n",
    "  - [Train and Evaluate](#toc2_3_)    \n",
    "  - [Visualize Results](#toc2_4_)    \n",
    "- [Fit a Neural Network](#toc3_)    \n",
    "  - [Filter and Prepare Datase](#toc3_1_)    \n",
    "  - [Define Train and Validation Sets](#toc3_2_)    \n",
    "  - [Train Simple Network](#toc3_3_)    \n",
    "  - [Visualize Training Results](#toc3_4_)    \n",
    "- [Run Inferance and Save Results](#toc4_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T16:21:41.796967Z",
     "iopub.status.busy": "2025-05-28T16:21:41.796667Z",
     "iopub.status.idle": "2025-05-28T16:21:41.803044Z",
     "shell.execute_reply": "2025-05-28T16:21:41.802069Z",
     "shell.execute_reply.started": "2025-05-28T16:21:41.796949Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "from matplotlib_inline.backend_inline import set_matplotlib_formats\n",
    "\n",
    "# teak some settings \n",
    "plt.style.use('ggplot')\n",
    "sns.set_context('notebook')\n",
    "set_matplotlib_formats('retina')\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-05-28T16:21:41.820804Z",
     "iopub.status.busy": "2025-05-28T16:21:41.820060Z",
     "iopub.status.idle": "2025-05-28T16:21:41.842127Z",
     "shell.execute_reply": "2025-05-28T16:21:41.841316Z",
     "shell.execute_reply.started": "2025-05-28T16:21:41.820764Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "for dirname, _, filenames in os.walk(os.getcwd()):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T16:21:41.843855Z",
     "iopub.status.busy": "2025-05-28T16:21:41.843491Z",
     "iopub.status.idle": "2025-05-28T16:21:41.847724Z",
     "shell.execute_reply": "2025-05-28T16:21:41.846791Z",
     "shell.execute_reply.started": "2025-05-28T16:21:41.843829Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# dataset directory\n",
    "data_dir = 'house-prices-advanced-regression-techniques/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(data_dir + 'train.csv')\n",
    "test_df = pd.read_csv(data_dir + 'test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc1_'></a>[Exploratory Data Analysis](#toc0_)\n",
    "- Feature Descriptions\n",
    "- Handeling Missing Values\n",
    "- Explore Categorical Features\n",
    "- Feature Manipulation\n",
    "- Explore Numerical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Train Shape: {train_df.shape}, Test Shape: {test_df.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_1_'></a>[Feature Descriptions](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'data_description.txt'\n",
    "with open(data_dir + file_name, 'r') as data_description:\n",
    "    description = data_description.read()\n",
    "\n",
    "print(description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_2_'></a>[Handeling Missing Values](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.isna().sum(axis=0).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T16:21:41.984113Z",
     "iopub.status.busy": "2025-05-28T16:21:41.983327Z",
     "iopub.status.idle": "2025-05-28T16:21:42.006821Z",
     "shell.execute_reply": "2025-05-28T16:21:42.005933Z",
     "shell.execute_reply.started": "2025-05-28T16:21:41.984088Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# sperate data into object/numerical features\n",
    "object_cols = train_df.columns[train_df.dtypes == 'object']\n",
    "numeric_cols = train_df.columns[(train_df.dtypes == 'int64') | (train_df.dtypes == 'float64')]\n",
    "\n",
    "print(f'Did i include all columns? --> {len(object_cols) + len(numeric_cols) == 81}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T16:21:42.008198Z",
     "iopub.status.busy": "2025-05-28T16:21:42.007936Z",
     "iopub.status.idle": "2025-05-28T16:21:42.038796Z",
     "shell.execute_reply": "2025-05-28T16:21:42.037724Z",
     "shell.execute_reply.started": "2025-05-28T16:21:42.008177Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "numeric_nulls = train_df[numeric_cols].isna().sum().sum()\n",
    "object_nulls = train_df[object_cols].isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_values = train_df.shape[0] * train_df.shape[1]\n",
    "print(f'Numeric Nulls: {numeric_nulls}/{total_values}, Object Nulls: {object_nulls}/{total_values}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_2_1_'></a>[Plotting Null Values in Object Columns](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_nulls_df = train_df[object_cols].isna().sum(axis=0).sort_values(ascending=False)\n",
    "\n",
    "object_labels = object_nulls_df.index\n",
    "object_nulls = object_nulls_df.values\n",
    "\n",
    "fig = plt.figure(figsize=(15, 5))\n",
    "\n",
    "palette = sns.color_palette('YlOrBr')[::-1]\n",
    "sns.barplot(x=object_labels, y=object_nulls, edgecolor='.0', palette=palette)\n",
    "\n",
    "plt.title('Nulls per Object Feature', fontsize=16, weight='bold')\n",
    "\n",
    "plt.xlabel('Feature', fontsize=12), plt.ylabel('Missing Values', fontsize=12)\n",
    "plt.xticks(fontsize=10, rotation=45, ha='right'), plt.yticks(fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "redundant_object_features = ['PoolQC', 'MiscFeature', 'Alley', 'Fence', 'MasVnrType', 'FireplaceQu']\n",
    "train_df.drop(redundant_object_features, axis=1, inplace=True)\n",
    "test_df.drop(redundant_object_features, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_2_2_'></a>[Plotting Null Values in Numeric Columns](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_nulls_df = train_df[numeric_cols].isna().sum(axis=0).sort_values(ascending=False)\n",
    "\n",
    "numeric_labels = numeric_nulls_df.index\n",
    "numeric_nulls = numeric_nulls_df.values\n",
    "\n",
    "fig = plt.figure(figsize=(15, 5))\n",
    "\n",
    "palette = sns.color_palette('Blues')[::-1]\n",
    "sns.barplot(x=numeric_labels, y=numeric_nulls, edgecolor='.0', palette=palette)\n",
    "\n",
    "plt.title('Nulls per Object Feature', fontsize=16, weight='bold')\n",
    "\n",
    "plt.xlabel('Feature', fontsize=12), plt.ylabel('Missing Values', fontsize=12)\n",
    "plt.xticks(fontsize=10, rotation=45, ha='right'), plt.yticks(fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T16:21:43.423904Z",
     "iopub.status.busy": "2025-05-28T16:21:43.423636Z",
     "iopub.status.idle": "2025-05-28T16:21:43.432279Z",
     "shell.execute_reply": "2025-05-28T16:21:43.431321Z",
     "shell.execute_reply.started": "2025-05-28T16:21:43.423884Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "redundant_numeric_features = ['LotFrontage', 'GarageYrBlt']\n",
    "train_df.drop(redundant_numeric_features, axis=1, inplace=True)\n",
    "test_df.drop(redundant_numeric_features, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_cols = train_df.columns[train_df.dtypes == 'object']\n",
    "numeric_cols = train_df.columns[(train_df.dtypes == 'int64') | (train_df.dtypes == 'float64')]\n",
    "print(f'Did i Drop Columns? --> {len(object_cols) + len(numeric_cols) < 81}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_3_'></a>[Explore Categorical Features](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots_in_sub = 4\n",
    "\n",
    "for i in range(0, len(object_cols), plots_in_sub):\n",
    "    features_in_sub = object_cols[i : i + plots_in_sub]\n",
    "    fig, axes = plt.subplots(1, len(features_in_sub), figsize=(15, 4))\n",
    "    \n",
    "    if len(features_in_sub) == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    for ax, feature in zip(axes, features_in_sub):\n",
    "        order = train_df[feature].value_counts().index\n",
    "        palette = sns.color_palette('Set1')\n",
    "\n",
    "        sns.countplot(data=train_df, x=feature, palette=palette, saturation=0.5,\n",
    "                      edgecolor='.0', ax=ax, order=order, alpha=0.9)\n",
    "\n",
    "        ax2 = ax.twinx()\n",
    "        mean_df = train_df.groupby(feature)['SalePrice'].mean().reindex(order).reset_index()\n",
    "        \n",
    "        sns.lineplot(data=mean_df, x=feature, y='SalePrice', ax=ax2, color='black', \n",
    "                     marker='o', markersize=7, linewidth=2.5, linestyle='--', alpha=0.80)\n",
    "\n",
    "        ax2.grid(False)\n",
    "        ax2.set_ylabel('')\n",
    "        ax2.set_yticks([])\n",
    "        ax2.tick_params(axis='y', length=7, labelleft=False)\n",
    "        \n",
    "        ax.set_title(f'Values for: {feature} + Mean SalePrice', fontsize=11)\n",
    "        ax.set_xlabel(''), ax.set_ylabel('Count')\n",
    "        ax.tick_params(axis='x', rotation=90, labelsize=7)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features with no large variability: Street, LandContour, Utilities, LotConfig, LandSlope, Condition1, Condition2, BldgType, RoofStyle, RoofMatl, ExterCond, BsmtCond, BsmtExposure, BsmtFinType2, Heating, CentralAir, Functional, GarageQual, GarageCond, PavedDrive, SaleType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = train_df.shape[1]\n",
    "features_to_drop = [\n",
    "    'Street', 'LandContour', 'Utilities', 'LotConfig', \n",
    "    'LandSlope', 'Condition1', 'Condition2', 'BldgType', \n",
    "    'RoofStyle', 'RoofMatl', 'ExterCond', 'BsmtCond', \n",
    "    'BsmtExposure', 'BsmtFinType2', 'Heating', 'CentralAir', \n",
    "    'Functional', 'GarageQual', 'GarageCond', \n",
    "    'PavedDrive', 'SaleType'\n",
    "    ]\n",
    "\n",
    "train_df.drop(features_to_drop, axis=1, inplace=True)\n",
    "test_df.drop(features_to_drop, axis=1, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "object_cols = train_df.columns[train_df.dtypes == 'object']\n",
    "numeric_cols = train_df.columns[(train_df.dtypes == 'int64') | (train_df.dtypes == 'float64')]\n",
    "print(f'Did i Drop Columns? --> {len(object_cols) + len(numeric_cols) < cols}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_3_1_'></a>[Sort by Mean Price](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots_in_sub = 3\n",
    "\n",
    "for i in range(0, len(object_cols), plots_in_sub):\n",
    "    features_in_sub = object_cols[i : i + plots_in_sub]\n",
    "    fig, axes = plt.subplots(1, len(features_in_sub), figsize=(15, 4))\n",
    "    \n",
    "    if len(features_in_sub) == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    for ax, feature in zip(axes, features_in_sub):\n",
    "        order = train_df.groupby(feature)['SalePrice'].mean().sort_values(ascending=False).index\n",
    "        \n",
    "        sns.countplot(data=train_df, x=feature, palette='Spectral', saturation=0.65,\n",
    "                      edgecolor='.0', ax=ax, order=order, alpha=0.9)\n",
    "\n",
    "        ax2 = ax.twinx()\n",
    "        mean_df = train_df.groupby(feature)['SalePrice'].mean().reindex(order).reset_index()\n",
    "        \n",
    "        sns.lineplot(data=mean_df, x=feature, y='SalePrice', ax=ax2, color='black', \n",
    "                     marker='o', markersize=7, linewidth=2.5, linestyle='--', alpha=0.80)\n",
    "\n",
    "        ax2.grid(False)\n",
    "        ax2.set_ylabel('')\n",
    "        ax2.set_ylabel('Mean SalePrice', fontsize=12)\n",
    "        ax2.yaxis.set_major_formatter(FuncFormatter(lambda x, _: f'{x/1000:.0f}k'))\n",
    "        ax2.tick_params(axis='y', length=7, labelleft=False)\n",
    "        \n",
    "        ax.set_title(f'Values for: {feature} + Mean SalePrice', fontsize=14)\n",
    "        ax.set_xlabel(''), ax.set_ylabel('Count', fontsize=12)\n",
    "        ax.tick_params(axis='x', rotation=90, labelsize=8)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_4_'></a>[Feature Manipulation](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "\n",
    "def print_columns(items, width=4):\n",
    "    rows = [items[i:i+width] for i in range(0, len(items), width)]\n",
    "    for row in rows:\n",
    "        print(\" | \".join(f\"{str(item):<15}\" for item in row))\n",
    "        \n",
    "for feature in object_cols:\n",
    "    categories = train_df.groupby(feature)['SalePrice'].mean().sort_values().index.tolist()\n",
    "    print(f\"\\n{feature} (ordered by mean SalePrice):\")\n",
    "    print_columns(categories, width=4)\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_4_1_'></a>[Feature Engeneering -](#toc0_)\n",
    "* **Electrical** (SBrkr, FuseA, FuseF, FuseP, Mix) $\\rightarrow$ (Standard{SBrkr}, Other{FuseA, FuseF, FuseP, Mix})\n",
    "* **BsmtFinType1** (GLQ, ALQ, BLQ, Rec, LwQ, Unf, NA) $\\rightarrow$ (Good{GLQ}, Average{ALQ, Rec}, Low{BLQ, LwQ, Unf}, NoBsmt{NA})\n",
    "* **Foundation** (BrkTil, CBlock, PConc, Slab, Wood) $\\rightarrow$ (CBlock, PConc, Other{BrkTil, Slab, Wood})\n",
    "* **GarageType** (2Types, Attchd, Detchd, Basment, BuiltIn, CarPort, NA) $\\rightarrow$ (BuiltIn, Attached{Attchd, Basment}, Detchd, Other{2Types, CarPort}, NA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engeneering\n",
    "# Electrical: ['SBrkr', 'FuseF', 'FuseA', 'FuseP', 'Mix', 'NA'] --> [Standard{SBrkr}, Other{FuseA, FuseF, FuseP, Mix, NA}]\n",
    "train_df['Electrical'].fillna('NA', inplace=True)\n",
    "train_df['BsmtFinType1'].fillna('NA', inplace=True)\n",
    "train_df['GarageType'].fillna('NA', inplace=True)\n",
    "\n",
    "test_df['Electrical'].fillna('NA', inplace=True)\n",
    "test_df['BsmtFinType1'].fillna('NA', inplace=True)\n",
    "test_df['GarageType'].fillna('NA', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T16:22:01.602995Z",
     "iopub.status.busy": "2025-05-28T16:22:01.602745Z",
     "iopub.status.idle": "2025-05-28T16:22:01.630789Z",
     "shell.execute_reply": "2025-05-28T16:22:01.629502Z",
     "shell.execute_reply.started": "2025-05-28T16:22:01.602976Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print('Before:', '\\n' + '-'*60)\n",
    "print('Electrical:', train_df['Electrical'].unique().tolist())\n",
    "print('BsmtFinType1:', train_df['BsmtFinType1'].unique().tolist())\n",
    "print('GarageType:', train_df['GarageType'].unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T16:22:01.632024Z",
     "iopub.status.busy": "2025-05-28T16:22:01.631795Z",
     "iopub.status.idle": "2025-05-28T16:22:01.661551Z",
     "shell.execute_reply": "2025-05-28T16:22:01.660411Z",
     "shell.execute_reply.started": "2025-05-28T16:22:01.632004Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Electrical: ['SBrkr', 'FuseF', 'FuseA', 'FuseP', 'Mix', 'NA'] --> [Standard{SBrkr}, Other{FuseA, FuseF, FuseP, Mix, NA}]\n",
    "# BsmtFinType1: [GLQ, ALQ, BLQ, Rec, LwQ, Unf, NA] --> [Good{GLQ}, Average{ALQ, Rec}, Low{BLQ, LwQ, Unf}, NA]\n",
    "# Foundation [BrkTil, CBlock, PConc, Slab, Wood] --> [CBlock, PConc, Other{BrkTil, Slab, Wood, Stone}]\n",
    "# GarageType [2Types, Attchd, Detchd, Basment, BuiltIn, CarPort, NA] --> [BuiltIn, Attached{Attchd, Basment}, Detchd, Other{2Types, CarPort}, NA]\n",
    "\n",
    "electrical_map = {\n",
    "    'SBrkr': 'Standard', \n",
    "    'FuseF': 'Other', \n",
    "    'FuseA': 'Other', \n",
    "    'FuseP': 'Other', \n",
    "    'Mix': 'Other', \n",
    "}\n",
    "bsmt_type_map = {\n",
    "    'GLQ': 'Good', \n",
    "    'ALQ': 'Average', \n",
    "    'BLQ': 'Low', \n",
    "    'Rec': 'Average', \n",
    "    'LwQ': 'Low', \n",
    "    'Unf': 'Low'\n",
    "}\n",
    "foundation_map = {\n",
    "    'BrkTil': 'Other', \n",
    "    'Slab': 'Other', \n",
    "    'Wood': 'Other',\n",
    "    'Stone': 'Other'\n",
    "}\n",
    "garage_type_map = {\n",
    "    '2Types': 'Other', \n",
    "    'Attchd': 'Attached', \n",
    "    'Detchd':'Detached', \n",
    "    'Basment': 'Attached',\n",
    "    'CarPort': 'Other'\n",
    "}\n",
    "\n",
    "train_df['Electrical'].replace(electrical_map, inplace=True)\n",
    "train_df['BsmtFinType1'].replace(bsmt_type_map, inplace=True)\n",
    "train_df['Foundation'].replace(foundation_map, inplace=True)\n",
    "train_df['GarageType'].replace(garage_type_map, inplace=True)\n",
    "\n",
    "test_df['Electrical'].replace(electrical_map, inplace=True)\n",
    "test_df['BsmtFinType1'].replace(bsmt_type_map, inplace=True)\n",
    "test_df['Foundation'].replace(foundation_map, inplace=True)\n",
    "test_df['GarageType'].replace(garage_type_map, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('After Feature Engineering:', '\\n' + '-'*35)\n",
    "print('Electrical:', train_df['Electrical'].unique().tolist())\n",
    "print('BsmtFinType1:', train_df['BsmtFinType1'].unique().tolist())\n",
    "print('Foundation:', train_df['Foundation'].unique().tolist())\n",
    "print('GarageType:', train_df['GarageType'].unique().tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_4_2_'></a>[Label Encoding -](#toc0_)\n",
    "* **ExterQual, BsmtQual, HeatingQC, KitchenQual** $\\rightarrow$ Fa{Po + Fa}, TA, Gd, Ex $\\rightarrow$ (0-4)\n",
    "* **GarageFinish** (NA, Unf, RFn, Fin) $\\rightarrow$ (0-3)\n",
    "* **Electrical** (Standard, Other, NA) $\\rightarrow$ (0-2)\n",
    "* **BsmtFinType1**: (Good, Average, Low, NA) $\\rightarrow$ (0-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['GarageFinish'].fillna('NA', inplace=True)\n",
    "test_df['GarageFinish'].fillna('NA', inplace=True)\n",
    "\n",
    "for qual_feature in ['ExterQual', 'BsmtQual', 'HeatingQC', 'KitchenQual']:\n",
    "    train_df[qual_feature].fillna('NA', inplace=True)\n",
    "    test_df[qual_feature].fillna('NA', inplace=True)\n",
    "    \n",
    "qual_df = train_df[['ExterQual', 'BsmtQual', 'HeatingQC', 'KitchenQual']]\n",
    "print(f'Did if fill the nulls --> {qual_df.isna().sum().sum() + train_df.GarageFinish.isna().sum().sum() == 0}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T16:22:01.711798Z",
     "iopub.status.busy": "2025-05-28T16:22:01.711484Z",
     "iopub.status.idle": "2025-05-28T16:22:01.744635Z",
     "shell.execute_reply": "2025-05-28T16:22:01.743472Z",
     "shell.execute_reply.started": "2025-05-28T16:22:01.711769Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "electrical_map = {'Standard': 2, 'Other': 1, 'NA': 0}\n",
    "bsmt_type_map = {'Good': 3, 'Average': 2, 'Low': 1, 'NA': 0}\n",
    "qual_map = {'NA': 0, 'Po': 1, 'Fa': 1, 'TA': 2, 'Gd': 3, 'Ex': 4}\n",
    "garage_fnsh_map = {'Fin': 3, 'RFn': 2, 'Unf': 1, 'NA': 0}\n",
    "\n",
    "train_df['Electrical'].replace(electrical_map, inplace=True)\n",
    "train_df['BsmtFinType1'].replace(bsmt_type_map, inplace=True)\n",
    "train_df['GarageFinish'].replace(garage_fnsh_map, inplace=True)\n",
    "\n",
    "test_df['Electrical'].replace(electrical_map, inplace=True)\n",
    "test_df['BsmtFinType1'].replace(bsmt_type_map, inplace=True)\n",
    "test_df['GarageFinish'].replace(garage_fnsh_map, inplace=True)\n",
    "\n",
    "for col in ['ExterQual', 'BsmtQual', 'HeatingQC', 'KitchenQual']:\n",
    "    train_df[col].replace(qual_map, inplace=True)\n",
    "    test_df[col].replace(qual_map, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoding_cols = ['Electrical', 'BsmtFinType1', 'GarageFinish', 'ExterQual', 'BsmtQual', 'HeatingQC', 'KitchenQual']\n",
    "for col in label_encoding_cols:\n",
    "    print(f\"{col} - unique values: {sorted(train_df[col].unique())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_4_3_'></a>[Target Encoding (LOO) -](#toc0_)\n",
    "* **MSZoning, LotShape, Neighborhood, HouseStyle, Exterior1st, Exterior2nd, SaleCondition**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leave_one_out_cols = [\n",
    "    'MSZoning', 'LotShape', 'Neighborhood', \n",
    "    'HouseStyle', 'Exterior1st', 'Exterior2nd', \n",
    "    'SaleCondition', 'Foundation', 'GarageType'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[leave_one_out_cols].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[leave_one_out_cols].isna().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# amount of unique categories before for each feature\n",
    "print('Number of Categories Within each Feature' + '\\n' + '-'*40)\n",
    "for col in leave_one_out_cols:\n",
    "    feature = col\n",
    "    unique_categories = train_df[col].nunique()\n",
    "    print(f'| {feature}: {unique_categories}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import TargetEncoder\n",
    "\n",
    "target_enc = TargetEncoder(target_type='continuous', cv=train_df.shape[0], shuffle=False)\n",
    "target_enc.fit(train_df[leave_one_out_cols], train_df['SalePrice'])\n",
    "\n",
    "train_df[leave_one_out_cols] = target_enc.transform(train_df[leave_one_out_cols])\n",
    "test_df[leave_one_out_cols] = target_enc.transform(test_df[leave_one_out_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nunique after\n",
    "print('Number of Categories Within each Feature' + '\\n' + '-'*40)\n",
    "for col in leave_one_out_cols:\n",
    "    feature = col\n",
    "    unique_categories = train_df[col].nunique()\n",
    "    print(f'| {feature}: {unique_categories}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[leave_one_out_cols].dtypes.to_frame().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond = sum((train_df.dtypes.values == 'object').tolist()) == 0\n",
    "print(f'Are all columns numeric? --> {cond}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_5_'></a>[Explore Numerical Features](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(x=train_df['SalePrice'], kde=True, bins=40)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots_in_sub = 5\n",
    "\n",
    "for i in range(0, len(numeric_cols), plots_in_sub):\n",
    "    features_in_sub = numeric_cols[i : i + plots_in_sub]\n",
    "    fig, axes = plt.subplots(1, len(features_in_sub), figsize=(15, 4))\n",
    "    \n",
    "    if len(features_in_sub) == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    for ax, feature in zip(axes, features_in_sub):\n",
    "        \n",
    "        sns.histplot(data=train_df, x=feature, kde=True, ax=ax)\n",
    "        ax.set_title(f'Distibution of {feature}', fontsize=11)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['SalePrice'] = np.log(train_df['SalePrice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.histplot(x=train_df['SalePrice'], kde=True, bins=40, color='blue')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_5_1_'></a>[Remove Outliers](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_trim = [\n",
    "    'SalePrice', 'LotArea', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2',\n",
    "    'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'GrLivArea',\n",
    "    'GarageArea', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch',\n",
    "]\n",
    "\n",
    "top_index_per_feature = {}\n",
    "for col in features_to_trim:\n",
    "    top_index_per_feature[col] = train_df[train_df[col] > train_df[col].quantile(.98)].index.tolist()\n",
    "\n",
    "print('Amout of Rows to Drop for each Feature' + '\\n' + '-'*40, end='')\n",
    "{key: len(indexes) for key, indexes in top_index_per_feature.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_indexes = set([\n",
    "    index\n",
    "    for indexes in top_index_per_feature.values()\n",
    "        for index in indexes\n",
    "])\n",
    "train_df.drop(unique_indexes, axis=0, inplace=True)\n",
    "print(f'Train Set Shape After Removal: {train_df.shape}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc2_'></a>[Training and Testing Linear Models](#toc0_)\n",
    "- Filter by Correlation\n",
    "- Prepare Data for Training\n",
    "- Train and Evaluate\n",
    "- Visualize Results\n",
    "- Run Inferance and Save Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc2_1_'></a>[Filter by Correlation](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_with_traget = abs(train_df.corr()['SalePrice']).sort_values(ascending=False).drop('SalePrice')\n",
    "sorted_corrs = corr_with_traget.sort_values(ascending=False)\n",
    "\n",
    "fig = plt.figure(figsize=(12, 4))\n",
    "\n",
    "sns.barplot(x=sorted_corrs.index, y=sorted_corrs.values, palette='Spectral', saturation=0.6, edgecolor=\".2\")\n",
    "\n",
    "plt.title('Correlation Between all Columns to SalePrice', fontsize=18, weight='bold')\n",
    "\n",
    "plt.xlabel('Feature', fontsize=14), plt.ylabel('Correlation', fontsize=14)\n",
    "plt.xticks(fontsize=10, rotation=45, ha='right'), plt.yticks(fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "inclue_feature = 10\n",
    "sampeld_cols = corr_with_traget.iloc[:inclue_feature].index.tolist()\n",
    "\n",
    "train_df_sub = train_df[sampeld_cols + ['SalePrice']]\n",
    "test_df_sub = test_df[sampeld_cols]\n",
    "\n",
    "print(f'Features in train_df_sub/test_df_sub ({len(sampeld_cols)}):')\n",
    "sampeld_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 7))\n",
    "\n",
    "sns.heatmap(train_df_sub.corr(), cmap='crest', annot=True, linewidths=0.4, square=True)\n",
    "\n",
    "plt.title('Feature Heatmap', weight='bold', pad=15, fontsize=18)\n",
    "plt.xticks(fontsize=10, rotation=45, ha='right'), plt.yticks(fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GarageCars Seems to have Large Correlation to GarageArea Which is Exected\n",
    "# In Using Linear Regression It's Better to Drop Highly Correlated Features from X set\n",
    "train_df_sub.drop('GarageCars', axis=1, inplace=True)\n",
    "test_df_sub.drop('GarageCars', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictors = train_df_sub.drop('SalePrice', axis=1).copy()\n",
    "train_predictors.fillna(0, inplace=True)\n",
    "\n",
    "test_predictors = test_df_sub.copy()\n",
    "test_predictors.fillna(0, inplace=True)\n",
    "\n",
    "train_target = train_df_sub['SalePrice'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc2_2_'></a>[Prepare for Training](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "def prepare_dataset(X_train_df, y_train_df, X_test_df, scale_target=False):\n",
    "    X_train, y_train, X_test = X_train_df.to_numpy().copy(), y_train_df.to_numpy().copy(), X_test_df.to_numpy().copy()\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    if scale_target:\n",
    "        return X_train_scaled, scaler.transform(y_train), X_test_scaled\n",
    "    \n",
    "    return X_train_scaled, y_train, X_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, y_train, X_test = prepare_dataset(train_predictors, train_target, test_predictors)\n",
    "\n",
    "# train 2/3 | validation 1/3\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.33, random_state=42)\n",
    "print(f'X_train :{X_train.shape}, X_val: {X_val.shape}, y_train: {y_train.shape}, y_test: {y_val.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc2_3_'></a>[Train and Evaluate](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.metrics import mean_squared_error, root_mean_squared_error\n",
    "\n",
    "regression_models = {\n",
    "    'Linear': LinearRegression(),\n",
    "    'Ridge': Ridge(alpha=1, max_iter=10000),\n",
    "    'Lasso': Lasso(alpha=0.1, max_iter=10000)\n",
    "}\n",
    "\n",
    "training_results = {'Train': {}, 'Validation': {}}\n",
    "for name, model in regression_models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    val_preds = model.predict(X_val)\n",
    "    train_perds = model.predict(X_train)\n",
    "\n",
    "    train_rsquared, val_rsquared = model.score(X_train, y_train) ,model.score(X_val, y_val)\n",
    "    train_mse, val_mse = mean_squared_error(y_train, train_perds) ,mean_squared_error(y_val, val_preds)\n",
    "    train_rmse, val_rmse = root_mean_squared_error(y_train, train_perds) ,root_mean_squared_error(y_val, val_preds)\n",
    "\n",
    "    training_results['Train'][name] = {'MSE': train_mse, 'RMSE': train_rmse, 'RSquared': train_rsquared}\n",
    "    training_results['Validation'][name] = {'MSE': val_mse, 'RMSE': val_rmse, 'RSquared': val_rsquared}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc2_4_'></a>[Visualize Results](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dfs = []\n",
    "for results_set in training_results:\n",
    "    df = pd.DataFrame(training_results[results_set]).T\n",
    "    df['Set'] = results_set\n",
    "    results_dfs.append(df)\n",
    "\n",
    "models_evaluation = pd.concat(results_dfs, axis=0)\n",
    "models_evaluation = models_evaluation.reset_index().rename(columns={'index': 'Model'}).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palette = sns.color_palette('tab10', desat=1)\n",
    "metrics = ['MSE', 'RMSE', 'RSquared']\n",
    "fig, axes = plt.subplots(1, len(metrics), figsize=(11, 4))\n",
    "\n",
    "for metric, ax in zip(metrics, axes):\n",
    "    sns.barplot(\n",
    "        data=models_evaluation, \n",
    "        x='Model', y=metric, hue='Set',\n",
    "        edgecolor='black',\n",
    "        ax=ax,\n",
    "        color=random.choice(palette)\n",
    "    )\n",
    "    ax.set_title(f'Train/Validation {metric}')\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_ylabel('')\n",
    "    ax.legend(loc='lower right', framealpha=1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print(pd.DataFrame(training_results['Validation']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc3_'></a>[Fit a Neural Network](#toc0_)\n",
    "- Filter and Prepare Dataset\n",
    "- Define Train and Validation Sets\n",
    "- Train Simple Network\n",
    "- Visualize Training Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc3_1_'></a>[Filter and Prepare Datase](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inclue_feature = None\n",
    "sampeld_cols = corr_with_traget.iloc[:inclue_feature].index.tolist()\n",
    "\n",
    "train_df_sub = train_df[sampeld_cols + ['SalePrice']]\n",
    "test_df_sub = test_df[sampeld_cols]\n",
    "\n",
    "print(f'Features in train_df_sub/test_df_sub ({len(sampeld_cols)}):')\n",
    "sampeld_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\"\"\n",
    "Missing Values in Train {train_df_sub.isna().sum().sum()}, Missing Values in Test {test_df_sub.isna().sum().sum()}\n",
    "-------------------------------------------------------------------\n",
    "Train Set Cols: {train_df_sub.columns[train_df_sub.isna().sum(axis=0) != 0].tolist()}\n",
    "Test Set Cols: {test_df_sub.columns[test_df_sub.isna().sum(axis=0) != 0].tolist()}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "all features with missing values are features that could not exist within a house so replacing them all with 0 seems like a good option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_sub.fillna(0, inplace=True)\n",
    "test_df_sub.fillna(0, inplace=True)\n",
    "print(f\"\"\"\n",
    "Missing Values in Train {train_df_sub.isna().sum().sum()}, Missing Values in Test {test_df_sub.isna().sum().sum()}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc3_2_'></a>[Define Train and Validation Sets](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, X_test = prepare_dataset(\n",
    "    X_train_df=train_df_sub.drop('SalePrice', axis=1).copy(), \n",
    "    y_train_df=train_df_sub['SalePrice'].copy(), \n",
    "    X_test_df=test_df_sub.copy()\n",
    ")\n",
    "# train 2/3 | validation 1/3\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "X_train = X_train.copy().astype(np.float32)\n",
    "X_val = X_val.copy().astype(np.float32)\n",
    "y_train = y_train.copy().astype(np.float32)\n",
    "y_val = y_val.copy().astype(np.float32)\n",
    "\n",
    "for name, arr in [(\"X_train\", X_train), (\"y_train\", y_train),\n",
    "                  (\"X_val\",  X_val),   (\"y_val\",  y_val)]:\n",
    "    print(f\"{name}: shape={arr.shape},  dtype={arr.dtype}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc3_3_'></a>[Train Simple Network](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, BatchNormalization, Activation, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError, MeanSquaredError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs =  Input(shape=(X_train.shape[1],), dtype=tf.float32)\n",
    "\n",
    "x = Dense(128)(inputs)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dropout(0.25)(x)\n",
    "\n",
    "x = Dense(64)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dropout(0.25)(x)\n",
    "\n",
    "x = Dense(32)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dropout(0.25)(x)\n",
    "\n",
    "outputs = Dense(1, activation='linear')(x)\n",
    "model = Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary(line_length=50, print_fn=print)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model.compile(\n",
    "   optimizer=Adam(learning_rate=1e-5),\n",
    "   loss='mse',\n",
    "   metrics=[\n",
    "       MeanSquaredError(name='MSE'), \n",
    "       RootMeanSquaredError(name='RMSE')\n",
    "       ],\n",
    ")\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    batch_size=32,\n",
    "    epochs=30,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc3_4_'></a>[Visualize Training Results](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 1\n",
    "history_df = pd.DataFrame(history.history).iloc[::step]\n",
    "fig = plt.figure(figsize=(6, 4))\n",
    "sns.lineplot(data=history_df[['loss', 'val_loss']], linewidth=2.5)\n",
    "plt.title('Title')\n",
    "plt.xlabel('X Label', fontsize=10), plt.ylabel('Y Label', fontsize=10)\n",
    "plt.xticks(fontsize=10), plt.yticks(fontsize=10)\n",
    "plt.legend(fontsize=10)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc4_'></a>[Run Inferance and Save Results](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use expm1 because we scaled sale price with log1p before training the model\n",
    "# y_test = np.expm1(regression_models['Linear'].predict(X_test))\n",
    "y_test = np.expm1(model.predict(X_test))\n",
    "\n",
    "# make submission dataframe\n",
    "test_df['SalePrice'] = y_test\n",
    "submission = test_df[['Id', 'SalePrice']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(7, 4))\n",
    "sns.histplot(x=submission['SalePrice'], kde=True, color='blue', bins=60)\n",
    "plt.title('Predicted Sale Prices Histogram')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('predictions.csv', index=False)\n",
    "print('Predictions Saved:')\n",
    "submission"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 868283,
     "sourceId": 5407,
     "sourceType": "competition"
    }
   ],
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
